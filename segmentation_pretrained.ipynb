{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scativa/IV-Colab/blob/main/segmentation_pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1 - Librerias\n",
        "\n",
        "##functions.py\n",
        "Reemplaza la lÃ­nea `import functions as func`"
      ],
      "metadata": {
        "id": "ryDySnX4psf8"
      },
      "id": "ryDySnX4psf8"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "'''\n",
        "Some times I need normalizad images\n",
        "'''\n",
        "def load_images(dir, filenames=None, norm=False):\n",
        "  if filenames is None:\n",
        "    print(f\"Cargando {len(os.listdir(dir))} imagenes... \")\n",
        "    filenames = os.listdir(dir) # Cuidado, esto no garantiza el orden.\n",
        "  else:\n",
        "    print(f\"load_images {len(filenames)}... \")\n",
        "\n",
        "  images = []\n",
        "  i = 0\n",
        "  for filename in filenames:\n",
        "    # print(f\"{filename}: {len(images)}/{len(filenames)}\",end=\"\\r\")\n",
        "    print(f\"{i}) {filename}\") # ,end=\"\\r\")\n",
        "    i+=1\n",
        "    image = cv2.imread(os.path.join(dir, filename))\n",
        "    if image is not None:\n",
        "      images.append(image.astype(np.float32))\n",
        "  # images = [cv2.imread(os.path.join(dir, filename)).astype(np.float32)\n",
        "  #         for filename in filenames\n",
        "  #         if cv2.imread(os.path.join(dir, filename)) is not None]\n",
        "  if norm:\n",
        "      images = [image / 255.0 for image in images]\n",
        "\n",
        "  # https://chatgpt.com/c/67fd5724-8164-8006-9367-780189493ee5\n",
        "  images = [cv2.resize(image, (224, 224)).astype(np.float32) for image in images]\n",
        "\n",
        "  return images\n",
        "\n",
        "\n",
        "def load_masks(dir_pores, image_filenames):\n",
        "\n",
        "  for filename in image_filenames:\n",
        "    if not os.path.exists(os.path.join(dir_pores, filename)):\n",
        "      print(f\"Warning: {os.path.join(dir_pores, filename)} does not exist\")\n",
        "\n",
        "  masks = [\n",
        "          cv2.imread(os.path.join(dir_pores, filename), cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
        "          # if os.path.exists(os.path.join(dir_pores, filename))\n",
        "          # else np.zeros((232, 180), dtype=np.float32)\n",
        "          for filename in image_filenames\n",
        "  ]\n",
        "  # https://chatgpt.com/c/67fd5724-8164-8006-9367-780189493ee5\n",
        "  masks = [cv2.resize(mask, (224, 224)).astype(np.float32) for mask in masks]\n",
        "  masks = [np.expand_dims(mask, axis=-1) for mask in masks] #adds a channel dimension to the masks\n",
        "\n",
        "\n",
        "  return masks\n",
        "\n",
        "# just to plot masks\n",
        "def plot_img_mask(img, mask, pred):\n",
        "\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(5, 15))\n",
        "\n",
        "    sub_plot = 0\n",
        "\n",
        "    if (img is not None):\n",
        "      axes[sub_plot].imshow(img)\n",
        "      axes[sub_plot].set_title('Image')\n",
        "      axes[sub_plot].axis('off')\n",
        "      sub_plot += 1\n",
        "\n",
        "    if (mask is not None):\n",
        "      axes[sub_plot].imshow(mask, cmap='gray')\n",
        "      axes[sub_plot].set_title('Mask')\n",
        "      axes[sub_plot].axis('off')\n",
        "      sub_plot += 1\n",
        "\n",
        "    if (pred is not None):\n",
        "      pred_mask = np.where(pred <= 0.5, 0, 1)\n",
        "\n",
        "      axes[sub_plot].imshow(pred_mask, cmap='gray')\n",
        "      axes[sub_plot].set_title('Predicted')\n",
        "      axes[sub_plot].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def augmented_dataset(dir_images, dir_mask, seed, norm):\n",
        "    # From \"Pores 03/28/25 -Seba- Basado en segmentation_own (DTE_fisuras).ipynb\"\n",
        "\n",
        "    # image_filenames = os.path.basename(sorted(os.listdir(dir_images)))\n",
        "    image_filenames = sorted(os.listdir(dir_images))\n",
        "\n",
        "    # https://chatgpt.com/c/681d085f-e2ec-8006-833f-939f942ffd5b\n",
        "    # Mejoras para la carga de imÃ¡genes\n",
        "    images = load_images(dir_images, image_filenames, norm)\n",
        "    # Get image filenames from loaded images\n",
        "    # image_filenames = [os.path.basename(image_path) for image_path in os.listdir(dir_images)]\n",
        "    # masks = load_masks(dir_pores)\n",
        "\n",
        "    masks_filenames = [f\"{(p:=img_name.split('-'))[0]}-{p[1]}-{p[4]}-avg{p[6][-7:]}\" for img_name in image_filenames]\n",
        "    print(image_filenames[0], masks_filenames[0])\n",
        "    masks = load_masks(dir_mask, masks_filenames)\n",
        "    # masks = load_masks(dir_mask, image_filenames)\n",
        "\n",
        "\n",
        "    X_train, X_test, y_train, y_test, filenames_train, filenames_test = train_test_split(images, masks, image_filenames, test_size=0.2, random_state=seed)\n",
        "\n",
        "    X_train[0].shape\n",
        "    y_train[0].shape\n",
        "    augmented_X_train = [cv2.flip(i, 1) for i in X_train]\n",
        "    augmented_y_train = [cv2.flip(i, 1) for i in y_train]\n",
        "    augmented_y_train = [np.expand_dims(mask, axis=-1) for mask in augmented_y_train ] #adds a channel dimension to the masks\n",
        "\n",
        "    # print(y_train[0].shape, augmented_y_train[0].shape)\n",
        "    X_train = np.array(X_train + augmented_X_train)\n",
        "    y_train = np.array(y_train + augmented_y_train)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "\n",
        "    # y_train = np.expand_dims(y_train, axis=-1)\n",
        "    # y_val = np.expand_dims(y_val, axis=-1)\n",
        "    # y_test = np.expand_dims(y_test, axis=-1)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, filenames_train, filenames_val, filenames_test\n",
        "\n",
        "def load_img_mask(dir_images, dir_mask, image_filenames, masks_filenames, norm):\n",
        "    print(f\"Cargando {len(image_filenames)} imagenes... \")\n",
        "    X = load_images(dir_images, image_filenames, norm)\n",
        "    # masks_filenames = [f\"{(p:=img_name.split('-'))[0]}-{p[1]}-{p[4]}-avg{p[6][-7:]}\" for img_name in image_filenames]\n",
        "    print(f\"Cargando {len(image_filenames)} mÃ¡scaras... \")\n",
        "    y = load_masks(dir_mask, masks_filenames)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def augmented_dataset_ETIl(dir_images, dir_mask, filenames_train, filenames_val, filenames_train_masks, filenames_val_masks, norm):\n",
        "# def augmented_dataset_ETIl(dir_images, dir_mask, filenames_train, filenames_val, filenames_test, filenames_train_masks, filenames_val_masks, filenames_test_masks, norm):\n",
        "\n",
        "    print(f\"Cargadno Train dataset\")\n",
        "    X_train, y_train = load_img_mask(dir_images, dir_mask, filenames_train, filenames_train_masks, norm)\n",
        "    print(f\"Cargadno Val dataset\")\n",
        "    X_val, y_val = load_img_mask(dir_images, dir_mask, filenames_val, filenames_val_masks, norm)\n",
        "    # print(f\"Cargadno Test dataset\")\n",
        "    # X_test, y_test = load_img_mask(dir_images, dir_mask, filenames_test, filenames_test_masks, norm)\n",
        "\n",
        "    augmented_X_train = [cv2.flip(i, 1) for i in X_train]\n",
        "    augmented_y_train = [cv2.flip(i, 1) for i in y_train]\n",
        "    augmented_y_train = [np.expand_dims(mask, axis=-1) for mask in augmented_y_train ] #adds a channel dimension to the masks\n",
        "\n",
        "    # print(y_train[0].shape, augmented_y_train[0].shape)\n",
        "    X_train = np.array(X_train + augmented_X_train)\n",
        "    y_train = np.array(y_train + augmented_y_train)\n",
        "\n",
        "    # X_test = np.array(X_test)\n",
        "    # y_test = np.array(y_test)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val\n",
        "    # return X_train, y_train, X_val, y_val, X_test, y_test, filenames_train, filenames_val, filenames_test\n",
        "\n",
        "\n",
        "def test_dataset(dir_images, dir_mask, seed, norm):\n",
        "  # sÃ³lo el conjunto definido para test\n",
        "  image_filenames = sorted(os.listdir(dir_images))\n",
        "\n",
        "  images = load_images(dir_images, image_filenames, norm)\n",
        "  # Get image filenames from loaded images\n",
        "  # image_filenames = [os.path.basename(image_path) for image_path in os.listdir(dir_images)]\n",
        "  # masks = load_masks(dir_pores)\n",
        "  masks = load_masks(dir_mask, image_filenames)\n",
        "\n",
        "  _, X_test, _, y_test, _, filenames_test = train_test_split(images, masks, test_size=0.2, random_state=seed)\n",
        "\n",
        "  # y_test = np.expand_dims(y_test, axis=-1)\n",
        "\n",
        "  return X_test, y_test, filenames_test\n",
        "\n",
        "'''\n",
        "If you want to show some other metrics, just uncomment\n",
        "'''\n",
        "def plot_history(history, x_lim, y_lim):\n",
        "    #val_iou_score = history.history['val_iou_score']\n",
        "    #iou_score = history.history['iou_score']\n",
        "    val_f1_score = history.history['val_f1-score']\n",
        "    #f1_score = history.history['f1-score']\n",
        "    val_loss = history.history['val_loss']\n",
        "    loss = history.history['loss']\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    #plt.plot(epochs, val_iou_score, 'b', label='Validation IoU Score')\n",
        "    #plt.plot(epochs, iou_score, 'g', label='IoU Score')\n",
        "    #plt.plot(epochs, f1_score, 'r', label='F1 Score')\n",
        "    plt.plot(epochs, val_f1_score, 'c', label='Validation F1 Score')\n",
        "    plt.plot(epochs, val_loss, 'm', label='Validation Loss')\n",
        "    plt.plot(epochs, loss, 'y', label='Training Loss')\n",
        "\n",
        "    plt.title('Training Metrics', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Score/Loss', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.xlim(1, x_lim)\n",
        "    plt.ylim(0, y_lim)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "H80FZsTspq9N"
      },
      "id": "H80FZsTspq9N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2 - Entorno"
      ],
      "metadata": {
        "id": "Y6FbynbEtxDc"
      },
      "id": "Y6FbynbEtxDc"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLY5vQB7tS_O",
        "outputId": "42e1ff44-e6d3-43d2-b33c-803fb46c1769"
      },
      "id": "jLY5vQB7tS_O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from time import process_time_ns\n",
        "import os\n",
        "\n",
        "import os, json\n",
        "\n",
        "json_path = os.path.join('/content/drive/MyDrive/', 'drvinfo.json')\n",
        "usr_drive = json.load(open(json_path)).get('username') if os.path.exists(json_path) else None\n",
        "\n",
        "base_paths = { # Path al\n",
        "    \"ppca.cnea\": '/content/drive/MyDrive/IV',\n",
        "    \"seba.cnea\": '/content/drive/MyDrive/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV',\n",
        "    \"scativa\": '/content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV'\n",
        "}\n",
        "base_path = base_paths[usr_drive]\n",
        "\n",
        "if not os.path.exists(base_path):\n",
        "  print(f'Carpeta inexistente \"{usr_drive}: {base_path}\"')\n",
        "else:\n",
        "  print(f'Utilizando carpeta  \"{usr_drive}: {base_path}\"')\n",
        "\n",
        "\n",
        "# import tensorflow as tf\n",
        "# # Setting GPU memory growth to True\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if gpus:\n",
        "#     print(f\"GPUs detected: {gpus}\")\n",
        "#     try:\n",
        "#         for gpu in gpus:\n",
        "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
        "#     except RuntimeError as e:\n",
        "#         print(e)\n",
        "\n",
        "\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n"
      ],
      "metadata": {
        "id": "u8K_GpqhP4P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22450d59-f4e5-46ea-a85b-4b1d4a445dd8"
      },
      "id": "u8K_GpqhP4P1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilizando carpeta  \"scativa: /content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Modelos"
      ],
      "metadata": {
        "id": "nCOSxDTSQvyK"
      },
      "id": "nCOSxDTSQvyK"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models\n",
        "import segmentation_models as sm\n",
        "from segmentation_models import get_preprocessing"
      ],
      "metadata": {
        "id": "o2HzQryYNA5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a1bc9e-df6f-4810-d097-48fe8daceb5d"
      },
      "id": "o2HzQryYNA5U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl.metadata (938 bytes)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from segmentation-models)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting image-classifiers==1.0.0 (from segmentation-models)\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting efficientnet==1.0.0 (from segmentation-models)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.14.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (0.4)\n",
            "Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
            "Segmentation Models: using `tf.keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import segmentation_models as sm\n",
        "\n",
        "# === Registro para serializaciÃ³n ===\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
        "def custom_bce_dice_loss(y_true, y_pred):\n",
        "    return sm.losses.bce_dice_loss(y_true, y_pred)\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
        "def custom_bce_jaccard_loss(y_true, y_pred):\n",
        "    return sm.losses.bce_jaccard_loss(y_true, y_pred)\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
        "def custom_iou_score(y_true, y_pred):\n",
        "    return sm.metrics.iou_score(y_true, y_pred)\n",
        "\n",
        "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
        "def custom_f1_score(y_true, y_pred):\n",
        "    return sm.metrics.f1_score(y_true, y_pred)"
      ],
      "metadata": {
        "id": "hIpHd0NwIEgk"
      },
      "id": "hIpHd0NwIEgk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "641b385e-a1d3-4289-bb59-6fb04559db85",
      "metadata": {
        "id": "641b385e-a1d3-4289-bb59-6fb04559db85"
      },
      "outputs": [],
      "source": [
        "model_resnet_152 = None\n",
        "model_vgg19 = None\n",
        "model_efficientnetb2 = None\n",
        "preprocess_input = None\n",
        "\n",
        "def create_model(model_type):\n",
        "  global model_resnet_152, model_vgg19, model_efficientnetb2, preprocess_input\n",
        "\n",
        "  if model_type == \"resnet152\":\n",
        "    print(\"Cargando ResNet152...\")\n",
        "    preprocess_input_resnet152 = get_preprocessing('resnet152')\n",
        "    preprocess_input = preprocess_input_resnet152\n",
        "    model_resnet_152 = sm.Unet(model_type, classes=1, activation='sigmoid', encoder_weights='imagenet')\n",
        "    model_resnet_152.compile(\n",
        "        'Adam',\n",
        "        loss=custom_bce_jaccard_loss, # Use the custom registered loss\n",
        "        metrics=[custom_iou_score, custom_f1_score],\n",
        "    )\n",
        "\n",
        "  elif model_type == \"vgg19\":\n",
        "    print(\"Cargando VGG19...\")\n",
        "    preprocess_input_vgg19 = get_preprocessing('vgg19')\n",
        "    model_vgg19 = sm.Unet(model_type, classes=1, activation='sigmoid', encoder_weights='imagenet')\n",
        "    model_vgg19.compile(\n",
        "        'Adam',\n",
        "        loss=custom_bce_jaccard_loss, # Use the custom registered loss\n",
        "        metrics=[custom_iou_score, custom_f1_score],\n",
        "    )\n",
        "\n",
        "  elif model_type == \"efficientnetb2\":\n",
        "    print(\"Cargando EfficientNetB2...\")\n",
        "    preprocess_input_efficientnetb2 = get_preprocessing('efficientnetb2')\n",
        "    model_efficientnetb2 = sm.Unet(model_type, classes=1, activation='sigmoid', encoder_weights='imagenet')\n",
        "    model_efficientnetb2.compile(\n",
        "        'Adam',\n",
        "        loss=custom_bce_jaccard_loss, # Use the custom registered loss\n",
        "        metrics=[custom_iou_score, custom_f1_score],\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Dataset"
      ],
      "metadata": {
        "id": "Tu8wymLMQsy6"
      },
      "id": "Tu8wymLMQsy6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f79518c-640f-483d-8465-4fa8fc47e4ad",
      "metadata": {
        "id": "0f79518c-640f-483d-8465-4fa8fc47e4ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618a1746-2284-46b0-d4c1-215bb630c3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilizando carpeta  \"scativa: /content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV\"\n",
            "Utilizando carpeta  \"scativa: /content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV\"\n"
          ]
        }
      ],
      "source": [
        "defect = 'pores' #'cachaduras'\n",
        "\n",
        "image_directory = f'{base_path}/Images/Output_imÃ¡genes y mÃ¡scaras 20250318/250127_p_2_i11'\n",
        "masks_directory = f'{base_path}/Images/Output_imÃ¡genes y mÃ¡scaras 20250318/all_{defect}_250520'\n",
        "# masks_directory = f'{base_path}/Images/Output_imÃ¡genes y mÃ¡scaras 20250318/all_cachaduras_250520'\n",
        "# masks_directory = f'{base_path}/Images/Output_imÃ¡genes y mÃ¡scaras 20250318/all_cachaduras'\n",
        "\n",
        "if not os.path.exists(image_directory):\n",
        "  print(f'Carpeta inexistente \"{usr_drive}: {base_path}\"')\n",
        "else:\n",
        "  print(f'Utilizando carpeta  \"{usr_drive}: {base_path}\"')\n",
        "\n",
        "if not os.path.exists(masks_directory):\n",
        "  print(f'Carpeta inexistente \"{usr_drive}: {base_path}\"')\n",
        "else:\n",
        "  print(f'Utilizando carpeta  \"{usr_drive}: {base_path}\"')\n",
        "\n",
        "# print(f\"{image_directory}: \",os.path.exists(image_directory))\n",
        "# print(f\"{masks_directory}: \",os.path.exists(masks_directory))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# https://chatgpt.com/c/6838bd09-1c94-8010-aae4-2ec5f990ecb7\n",
        "\n",
        "class SegmentationDataGenerator(tf.keras.utils.Sequence):\n",
        "    # def __init__(self, img_dir, mask_dir, img_filenames, mask_filenames,\n",
        "    #              batch_size=8, preprocess_fn=None, norm=True,\n",
        "    #              shuffle=True, augment=False):\n",
        "    def __init__(self, img_dir, mask_dir, samples, fn_data,\n",
        "                 batch_size=8, preprocess_fn=None, norm=True,\n",
        "                 shuffle=True, augment=False):\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "\n",
        "        self.samples = samples\n",
        "        # self.img_filenames = img_filenames\n",
        "        # self.mask_filenames = mask_filenames\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.preprocess_fn = preprocess_fn\n",
        "        self.norm = norm\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.indices = np.arange(len(self.samples))\n",
        "        # self.indices = np.arange(len(self.img_filenames))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "        self.fn_data = fn_data\n",
        "        #  {\n",
        "        #   \"fecha\": \"250127\",\n",
        "        #   \"series\": [\"BA\"],\n",
        "        #   # \"rotaciones\": [\n",
        "        #   #   \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\",\n",
        "        #   #   \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\",\n",
        "        #   #   \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\",\n",
        "        #   #   \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\",\n",
        "        #   #   \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\"\n",
        "        #   # ],\n",
        "        #   \"iluminaciones\": [\n",
        "        #     \"0-11000000\", \"0-00110000\", \"0-00001100\", \"0-00000011\", \"1-11000000\"],\n",
        "        #   \"ET\": [\n",
        "        #     \"30000.00\", \"32000.00\", \"34000.00\", \"36000.00\", \"38000.00\"],\n",
        "        #   # \"hileras\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n",
        "        #   # \"filas\": [\"0\", \"1\", \"2\", \"3\", \"4\"],\n",
        "        #   \"ext\": \"png\",\n",
        "\n",
        "        #   \"fn_img_patt\": \"{fecha}-r{rotacion}-i{iluminacion}-{serie}-ET{et}-a0000_{pastilla}.{ext}\",\n",
        "        #   \"fn_msk_patt\": \"{fecha}-r{rotacion}-{serie}-avg_{pastilla}.{ext}\"\n",
        "\n",
        "        # }\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.samples) / self.batch_size))\n",
        "        # return int(np.ceil(len(self.img_filenames) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        idxs = self.indices[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        batch_imgs = []\n",
        "        batch_masks = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for i in idxs:\n",
        "            r, p = self.samples[i].split(\"-\")\n",
        "            r = r[1:]\n",
        "\n",
        "            img_filename = self.fn_data[\"fn_img_patt\"].format(\n",
        "                fecha=self.fn_data[\"fecha\"],\n",
        "                rotacion=r,\n",
        "                iluminacion=random.choice(self.fn_data[\"iluminaciones\"]),\n",
        "                serie=self.fn_data[\"series\"][0],\n",
        "                et=random.choice(self.fn_data[\"ET\"]),\n",
        "                pastilla=p,\n",
        "                ext=self.fn_data[\"ext\"]\n",
        "            )\n",
        "\n",
        "            msk_filename = self.fn_data[\"fn_msk_patt\"].format(\n",
        "                fecha=self.fn_data[\"fecha\"],\n",
        "                rotacion=r,\n",
        "                serie=self.fn_data[\"series\"][0],\n",
        "                pastilla=p,\n",
        "                ext=self.fn_data[\"ext\"]\n",
        "            )\n",
        "\n",
        "            img_path = os.path.join(self.img_dir, img_filename)\n",
        "            mask_path = os.path.join(self.mask_dir, msk_filename)\n",
        "            # print(self.samples[i], img_filename, msk_filename) # Avoid excessive printing during training\n",
        "\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            if img is None:\n",
        "                print(f\"âš ï¸ Could not load image: {img_path}\")\n",
        "                continue\n",
        "            if mask is None:\n",
        "                print(f\"âš ï¸ Could not load mask: {mask_path}\")\n",
        "                continue\n",
        "\n",
        "            img = cv2.resize(img, (224, 224))\n",
        "            mask = cv2.resize(mask, (224, 224))\n",
        "\n",
        "            if self.norm:\n",
        "                img = img.astype(np.float32) / 255.0\n",
        "                mask = mask.astype(np.float32) / 255.0\n",
        "            else:\n",
        "                img = img.astype(np.float32)\n",
        "                mask = mask.astype(np.float32)\n",
        "\n",
        "            # AumentaciÃ³n: Flip horizontal aleatorio\n",
        "            if self.augment and random.random() < 0.5:\n",
        "                img = cv2.flip(img, 1)\n",
        "                mask = cv2.flip(mask, 1)\n",
        "\n",
        "            if mask.ndim == 2:\n",
        "                mask = np.expand_dims(mask, axis=-1)  # ahora shape (224, 224, 1)\n",
        "\n",
        "            # Ensure image has 3 channels for preprocessing\n",
        "            if img.ndim == 2:\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "            elif img.shape[-1] == 4: # Handle images with alpha channel\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGRA2RGB)\n",
        "\n",
        "            if img.shape != (224, 224, 3):\n",
        "                 print(f\"âš ï¸ Unexpected shape for image: {img.shape} ({img_path})\")\n",
        "                 continue\n",
        "\n",
        "            if mask.shape != (224, 224, 1):\n",
        "              print(f\"âš ï¸ Unexpected shape for mask: {mask.shape} ({mask_path})\")\n",
        "              continue\n",
        "\n",
        "\n",
        "            # Preprocesamiento especÃ­fico de la red (como ResNet152)\n",
        "            if self.preprocess_fn:\n",
        "                img = self.preprocess_fn(img)\n",
        "\n",
        "            batch_imgs.append(img)\n",
        "            batch_masks.append(mask)\n",
        "\n",
        "        # Handle case where no valid images/masks were loaded in the batch\n",
        "        if not batch_imgs:\n",
        "            return np.empty((0, 224, 224, 3), dtype=np.float32), np.empty((0, 224, 224, 1), dtype=np.float32)\n",
        "\n",
        "\n",
        "        return np.array(batch_imgs), np.array(batch_masks)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "LUcZmsPXIrDG"
      },
      "id": "LUcZmsPXIrDG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train, y_train, X_val, y_val, X_test, y_test, filenames_train, filenames_val, filenames_test = augmented_dataset(image_directory, masks_directory, seed=42, norm=False)"
      ],
      "metadata": {
        "id": "E6zrvrCuVize"
      },
      "id": "E6zrvrCuVize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(f'{base_path}/output/filenames_train.txt', 'w', encoding='utf-8') as f:\n",
        "#     for elemento in filenames_train:\n",
        "#         f.write(elemento + '\\n')\n",
        "# with open(f'{base_path}/output/filenames_val.txt', 'w', encoding='utf-8') as f:\n",
        "#     for elemento in filenames_val:\n",
        "#         f.write(elemento + '\\n')\n",
        "# with open(f'{base_path}/output/filenames_test.txt', 'w', encoding='utf-8') as f:\n",
        "#     for elemento in filenames_test:\n",
        "#         f.write(elemento + '\\n')\n"
      ],
      "metadata": {
        "id": "9wTGNdtl3kZv"
      },
      "id": "9wTGNdtl3kZv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(f'{base_path}/Datasets/train_images.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_train = [linea.strip() for linea in f]\n",
        "\n",
        "# with open(f'{base_path}/Datasets/test_images.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_test = [linea.strip() for linea in f]\n",
        "\n",
        "# with open(f'{base_path}/Datasets/val_images.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_val = [linea.strip() for linea in f]\n",
        "\n",
        "# with open(f'{base_path}/Datasets/train_masks.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_train_masks = [linea.strip() for linea in f]\n",
        "\n",
        "# with open(f'{base_path}/Datasets/test_masks.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_test_masks = [linea.strip() for linea in f]\n",
        "\n",
        "# with open(f'{base_path}/Datasets/val_masks.txt', 'r', encoding='utf-8') as f:\n",
        "#     filenames_val_masks = [linea.strip() for linea in f]\n",
        "\n",
        "# print(len(filenames_train), len(filenames_test), len(filenames_val))\n",
        "# print(len(filenames_train_masks), len(filenames_test_masks), len(filenames_val_masks))"
      ],
      "metadata": {
        "id": "J4z1HGUrP6k9"
      },
      "id": "J4z1HGUrP6k9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'{base_path}/Datasets/train_samples.txt', 'r', encoding='utf-8') as f:\n",
        "    filenames_train = [linea.strip() for linea in f]\n",
        "\n",
        "with open(f'{base_path}/Datasets/test_samples.txt', 'r', encoding='utf-8') as f:\n",
        "    filenames_test = [linea.strip() for linea in f]\n",
        "\n",
        "with open(f'{base_path}/Datasets/val_samples.txt', 'r', encoding='utf-8') as f:\n",
        "    filenames_val = [linea.strip() for linea in f]"
      ],
      "metadata": {
        "id": "nPBP6lqSwuiB"
      },
      "id": "nPBP6lqSwuiB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fn_data = {\n",
        "  \"fecha\": \"250127\",\n",
        "  \"series\": [\"BA\"],\n",
        "  # \"rotaciones\": [\n",
        "  #   \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\",\n",
        "  #   \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\",\n",
        "  #   \"21\", \"22\", \"23\", \"24\", \"25\", \"26\", \"27\", \"28\", \"29\", \"30\",\n",
        "  #   \"31\", \"32\", \"33\", \"34\", \"35\", \"36\", \"37\", \"38\", \"39\", \"40\",\n",
        "  #   \"41\", \"42\", \"43\", \"44\", \"45\", \"46\", \"47\", \"48\", \"49\", \"50\"\n",
        "  # ],\n",
        "  \"iluminaciones\": [\"0-11000000\", \"0-00110000\", \"0-00001100\", \"0-00000011\", \"1-11000000\"],\n",
        "  \"ET\": [\"30000.00\", \"32000.00\", \"34000.00\", \"36000.00\", \"38000.00\"],\n",
        "  # \"hileras\": [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"],\n",
        "  # \"filas\": [\"0\", \"1\", \"2\", \"3\", \"4\"],\n",
        "  \"ext\": \"png\",\n",
        "  \"fn_img_patt\": \"{fecha}-r{rotacion}-i{iluminacion}-{serie}-ET{et}-a0000_{pastilla}.{ext}\",\n",
        "  \"fn_msk_patt\": \"{fecha}-r{rotacion}-{serie}-avg_{pastilla}.{ext}\"\n",
        "}\n",
        "\n",
        "\n",
        "train_gen = SegmentationDataGenerator(\n",
        "    image_directory, masks_directory,\n",
        "    filenames_train,\n",
        "    fn_data,\n",
        "    # filenames_train, filenames_train_masks,\n",
        "    batch_size=8,\n",
        "    preprocess_fn=preprocess_input,\n",
        "    norm=True,\n",
        "    shuffle=True,\n",
        "    augment=True\n",
        ")\n",
        "\n",
        "val_gen = SegmentationDataGenerator(\n",
        "    image_directory, masks_directory,\n",
        "    filenames_val, # filenames_val_masks,\n",
        "    fn_data,\n",
        "    batch_size=8,\n",
        "    preprocess_fn=preprocess_input,\n",
        "    norm=True,\n",
        "    shuffle=False,\n",
        "    augment=False\n",
        ")"
      ],
      "metadata": {
        "id": "XPVgrHYNJy4q"
      },
      "id": "XPVgrHYNJy4q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_gen.samples[train_gen.indices[0]]\n",
        "# r = train_gen[0]"
      ],
      "metadata": {
        "id": "ySvQRztMyEWx"
      },
      "id": "ySvQRztMyEWx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # X_train, y_train, X_val, y_val, X_test, y_test = augmented_dataset_ETIl(image_directory, masks_directory,\n",
        "# X_train, y_train, X_val, y_val, = augmented_dataset_ETIl(image_directory, masks_directory,\n",
        "#                                                                         filenames_train, filenames_val,\n",
        "#                                                                         filenames_train_masks, filenames_val_masks,\n",
        "#                                                                         norm=False)"
      ],
      "metadata": {
        "id": "q1726LNlupP8"
      },
      "id": "q1726LNlupP8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 - Entrenamiento"
      ],
      "metadata": {
        "id": "PDGS_M--Crmd"
      },
      "id": "PDGS_M--Crmd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ParÃ¡metros"
      ],
      "metadata": {
        "id": "KhWLUYvzqFi5"
      },
      "id": "KhWLUYvzqFi5"
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16\n",
        "epochs=500\n",
        "patience=30 #20\n"
      ],
      "metadata": {
        "id": "27Dk-xbrpRfC"
      },
      "id": "27Dk-xbrpRfC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "p3dGCzlCNTF8"
      },
      "id": "p3dGCzlCNTF8"
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# import datetime\n",
        "import pytz\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "tz = pytz.timezone('America/Argentina/Buenos_Aires')\n",
        "\n",
        "class EpochTimingCallback(Callback):\n",
        "    def __init__(self, timezone_str='America/Argentina/Buenos_Aires'):\n",
        "        super().__init__()\n",
        "        self.tz = pytz.timezone(timezone_str)\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.epoch_start = datetime.now(self.tz)\n",
        "        print(f\"ğŸŸ¢ Epoch {epoch+1} - Inicio: {self.epoch_start.strftime('%Y-%m-%d %H:%M:%S')} (GMT-3)\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_end = datetime.now(self.tz)\n",
        "        duration = epoch_end - self.epoch_start\n",
        "        print(f\"\\nğŸ”´ Epoch {epoch+1} - Fin: {epoch_end.strftime('%Y-%m-%d %H:%M:%S')} (GMT-3) - DuraciÃ³n: {duration}\")\n",
        "\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(patience=patience,monitor='val_loss', restore_best_weights=True) # EarlyStopping(patience=10, restore_best_weights=True),"
      ],
      "metadata": {
        "id": "IUwrYdrwOh6v"
      },
      "id": "IUwrYdrwOh6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
        "\n",
        "# === 3. Callback mejorado para guardar historial .pkl y actualizar .csv ===\n",
        "class HistorySaver(Callback):\n",
        "    def __init__(self, pkl_path, csv_path):\n",
        "        super().__init__()\n",
        "        self.pkl_path = pkl_path\n",
        "        self.csv_path = csv_path\n",
        "\n",
        "        # Cargar historial CSV existente si hay\n",
        "        if os.path.exists(csv_path):\n",
        "            self.df_history = pd.read_csv(csv_path, index_col=\"epoch\")\n",
        "        else:\n",
        "            self.df_history = pd.DataFrame()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        new_row = pd.DataFrame([logs], index=[epoch])\n",
        "        new_row.index.name = 'epoch'\n",
        "\n",
        "        # Agregar nueva fila al historial existente\n",
        "        self.df_history = pd.concat([self.df_history, new_row])\n",
        "        self.df_history = self.df_history[~self.df_history.index.duplicated(keep='last')]\n",
        "        self.df_history.sort_index(inplace=True)\n",
        "\n",
        "        # Guardar como CSV\n",
        "        self.df_history.to_csv(self.csv_path)\n",
        "        print(f\"ğŸ“ CSV actualizado hasta Ã©poca {epoch + 1}\")\n",
        "\n",
        "        # TambiÃ©n guardar como .pkl para reanudar\n",
        "        with open(self.pkl_path, 'wb') as f:\n",
        "            pickle.dump(self.df_history.to_dict(orient='list'), f)\n",
        "\n",
        "# === 4. FunciÃ³n para verificar historial vÃ¡lido ===\n",
        "def valid_history(hist):\n",
        "    return (\n",
        "        isinstance(hist, dict) and\n",
        "        'loss' in hist and\n",
        "        isinstance(hist['loss'], list) and\n",
        "        len(hist['loss']) > 0\n",
        "    )"
      ],
      "metadata": {
        "id": "MFMURAwHJ3D9"
      },
      "id": "MFMURAwHJ3D9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "model_type = \"resnet152\"\n",
        "model_id = \"20250721_195907_resnet152_pores-m250520\"\n",
        "# model_id = None\n",
        "\n",
        "if not model_id:\n",
        "  # Nuevo modelo Identifica la corrida en particular\n",
        "  now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "  model_id = f'{now}_{model_type}_{defect}_m250520'\n",
        "  print(f\"Nuevo modelo: {model_id}\")\n",
        "else:\n",
        "  print(f\"Modelo existente: {model_id}\")\n",
        "\n",
        "# Modelo en proceso\n"
      ],
      "metadata": {
        "id": "2ysWU81oJSI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4d8574-93ab-4d27-b302-f3eb5b680f3e"
      },
      "id": "2ysWU81oJSI9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo existente: 20250721_195907_resnet152_pores-m250520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ResNet152"
      ],
      "metadata": {
        "id": "F_g9H76oRDB6"
      },
      "id": "F_g9H76oRDB6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5206106f-91a2-4863-b522-fa7a01b645b6",
      "metadata": {
        "id": "5206106f-91a2-4863-b522-fa7a01b645b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ed18ce-7f37-4c49-d405-db5cf204fb6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20250721_195907_resnet152_pores-m250520\n",
            "ğŸ” Cargando modelo completo desde: /content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV/model/checkpoints_20250721_195907_resnet152_pores-m250520/last.keras\n",
            "ğŸ“ˆ Historial cargado con 38 Ã©pocas.\n",
            "Comienzo entrenamiento: 2025-07-22 11:51:51.274189-03:00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš ï¸ Could not load image: /content/drive/MyDrive/Laburo/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV/Images/Output_imÃ¡genes y mÃ¡scaras 20250318/250127_p_2_i11/250127-r13-i0-11000000-BA-ET32000.00-a0000_A1.png\n",
            "ğŸŸ¢ Epoch 39 - Inicio: 2025-07-22 11:55:04 (GMT-3)\n",
            "Epoch 39/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - custom_f1_score: 0.3912 - custom_iou_score: 0.2658 - loss: 0.7504 \n",
            "ğŸ”´ Epoch 39 - Fin: 2025-07-22 12:33:20 (GMT-3) - DuraciÃ³n: 0:38:16.288460\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 39\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2304s\u001b[0m 16s/step - custom_f1_score: 0.3912 - custom_iou_score: 0.2659 - loss: 0.7504 - val_custom_f1_score: 0.1700 - val_custom_iou_score: 0.1002 - val_loss: 0.9202\n",
            "ğŸŸ¢ Epoch 40 - Inicio: 2025-07-22 12:33:27 (GMT-3)\n",
            "Epoch 40/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - custom_f1_score: 0.4458 - custom_iou_score: 0.3077 - loss: 0.7048\n",
            "ğŸ”´ Epoch 40 - Fin: 2025-07-22 12:52:35 (GMT-3) - DuraciÃ³n: 0:19:07.442742\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 40\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 9s/step - custom_f1_score: 0.4457 - custom_iou_score: 0.3077 - loss: 0.7048 - val_custom_f1_score: 0.3478 - val_custom_iou_score: 0.2318 - val_loss: 0.7745\n",
            "ğŸŸ¢ Epoch 41 - Inicio: 2025-07-22 12:52:43 (GMT-3)\n",
            "Epoch 41/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - custom_f1_score: 0.4140 - custom_iou_score: 0.2885 - loss: 0.7226\n",
            "ğŸ”´ Epoch 41 - Fin: 2025-07-22 13:11:34 (GMT-3) - DuraciÃ³n: 0:18:51.524175\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 41\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1145s\u001b[0m 9s/step - custom_f1_score: 0.4141 - custom_iou_score: 0.2885 - loss: 0.7226 - val_custom_f1_score: 0.3218 - val_custom_iou_score: 0.2154 - val_loss: 0.7906\n",
            "ğŸŸ¢ Epoch 42 - Inicio: 2025-07-22 13:11:48 (GMT-3)\n",
            "Epoch 42/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7s/step - custom_f1_score: 0.4118 - custom_iou_score: 0.2817 - loss: 0.7285\n",
            "ğŸ”´ Epoch 42 - Fin: 2025-07-22 13:29:24 (GMT-3) - DuraciÃ³n: 0:17:35.557163\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 42\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1063s\u001b[0m 8s/step - custom_f1_score: 0.4117 - custom_iou_score: 0.2816 - loss: 0.7286 - val_custom_f1_score: 0.2533 - val_custom_iou_score: 0.1530 - val_loss: 0.8624\n",
            "ğŸŸ¢ Epoch 43 - Inicio: 2025-07-22 13:29:31 (GMT-3)\n",
            "Epoch 43/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_f1_score: 0.4079 - custom_iou_score: 0.2776 - loss: 0.7370\n",
            "ğŸ”´ Epoch 43 - Fin: 2025-07-22 13:46:14 (GMT-3) - DuraciÃ³n: 0:16:43.525974\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 43\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1011s\u001b[0m 8s/step - custom_f1_score: 0.4078 - custom_iou_score: 0.2776 - loss: 0.7371 - val_custom_f1_score: 0.3733 - val_custom_iou_score: 0.2466 - val_loss: 0.7598\n",
            "ğŸŸ¢ Epoch 44 - Inicio: 2025-07-22 13:46:21 (GMT-3)\n",
            "Epoch 44/500\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - custom_f1_score: 0.4129 - custom_iou_score: 0.2869 - loss: 0.7195\n",
            "ğŸ”´ Epoch 44 - Fin: 2025-07-22 14:02:24 (GMT-3) - DuraciÃ³n: 0:16:02.906783\n",
            "ğŸ“ CSV actualizado hasta Ã©poca 44\n",
            "\u001b[1m132/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m972s\u001b[0m 7s/step - custom_f1_score: 0.4129 - custom_iou_score: 0.2869 - loss: 0.7196 - val_custom_f1_score: 0.3196 - val_custom_iou_score: 0.2110 - val_loss: 0.7972\n",
            "ğŸŸ¢ Epoch 45 - Inicio: 2025-07-22 14:02:33 (GMT-3)\n",
            "Epoch 45/500\n",
            "\u001b[1m 82/132\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4:52\u001b[0m 6s/step - custom_f1_score: 0.4449 - custom_iou_score: 0.3061 - loss: 0.7077"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "# === 2. Rutas ===\n",
        "out_folder = f'{base_path}/output/models'\n",
        "\n",
        "checkpoint_path = f\"{base_path}/model/checkpoints_{model_id}/last.keras\"\n",
        "history_pkl_path = f\"{base_path}/model/checkpoints_{model_id}/history.pkl\"\n",
        "history_csv_path = f\"{base_path}/model/checkpoints_{model_id}/history.csv\"\n",
        "\n",
        "# Crear carpeta de logs con timestamp\n",
        "log_dir = f'{base_path}/output/logs/fit/{model_id}'\n",
        "\n",
        "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "os.makedirs(out_folder, exist_ok=True)\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "# Callbacks\n",
        "timing_cb = EpochTimingCallback()\n",
        "\n",
        "tensorboard_cb = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "print(f\"{model_id}\")\n",
        "\n",
        "# train_gen.preprocess_fn = get_preprocessing('resnet152')\n",
        "# val_gen.preprocess_fn = get_preprocessing('resnet152')\n",
        "\n",
        "steps_per_epoch = len(train_gen)\n",
        "validation_steps = len(val_gen)\n",
        "\n",
        "if model_type == \"resnet152\":\n",
        "  # X_train_resnet = preprocess_input_resnet152(X_train)\n",
        "  # X_val_resnet = preprocess_input_resnet152(X_val)\n",
        "\n",
        "  # === 5. Cargar o crear modelo ===\n",
        "  if os.path.exists(checkpoint_path):\n",
        "      print(f\"ğŸ” Cargando modelo completo desde: {checkpoint_path}\")\n",
        "      model = tf.keras.models.load_model(\n",
        "          checkpoint_path,\n",
        "          custom_objects={\n",
        "              'custom_bce_dice_loss': custom_bce_dice_loss,\n",
        "              'custom_bce_jaccard_loss': custom_bce_jaccard_loss, # Add the custom jaccard loss\n",
        "              'custom_iou_score': custom_iou_score,\n",
        "              'custom_f1_score': custom_f1_score\n",
        "          }\n",
        "      )\n",
        "  else:\n",
        "      print(\"ğŸ†• Creando modelo desde cero.\")\n",
        "      create_model(model_type)\n",
        "      model = model_resnet_152\n",
        "\n",
        "  # === 6. Cargar historial si existe ===\n",
        "  if os.path.exists(history_pkl_path):\n",
        "      with open(history_pkl_path, 'rb') as f:\n",
        "          previous_history = pickle.load(f)\n",
        "      if valid_history(previous_history):\n",
        "          print(f\"ğŸ“ˆ Historial cargado con {len(previous_history['loss'])} Ã©pocas.\")\n",
        "      else:\n",
        "          previous_history = None\n",
        "          os.remove(history_pkl_path)\n",
        "          print(\"âš ï¸ Historial invÃ¡lido. Se iniciarÃ¡ desde cero.\")\n",
        "  else:\n",
        "      previous_history = None\n",
        "      print(\"ğŸ“‰ No se encontrÃ³ historial previo.\")\n",
        "\n",
        "  initial_epoch = len(previous_history['loss']) if previous_history else 0\n",
        "\n",
        "  # === 7. Entrenamiento ===\n",
        "  print(f'Comienzo entrenamiento: {datetime.now(tz)}')\n",
        "  history=model.fit(\n",
        "      # x=X_train_resnet,\n",
        "      # y=y_train,\n",
        "\n",
        "      train_gen,\n",
        "      validation_data=val_gen,\n",
        "\n",
        "      steps_per_epoch=steps_per_epoch,\n",
        "      validation_steps=validation_steps,\n",
        "\n",
        "      # batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      initial_epoch=initial_epoch,\n",
        "      # validation_data=(X_val_resnet, y_val),\n",
        "      callbacks=[\n",
        "          early_stopping_cb, tensorboard_cb, timing_cb,\n",
        "          ModelCheckpoint(checkpoint_path, save_best_only=False),\n",
        "          HistorySaver(history_pkl_path, history_csv_path)\n",
        "      ],\n",
        "  )\n",
        "  print(f'Fin entrenamiento: {datetime.now(tz)}')\n",
        "\n",
        "  print(f\"Saving Model {os.path.join(out_folder,model_id)}.keras...\")\n",
        "  model.save(os.path.join(out_folder,f'{model_id}.keras'))\n",
        "\n",
        "  print(\n",
        "      f\"batch_size: {batch_size}\",\" - \",\n",
        "      f\"epochs: {epochs}\",\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EvaluaciÃ³n"
      ],
      "metadata": {
        "id": "j95Def0xbctf"
      },
      "id": "j95Def0xbctf"
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/drive/MyDrive/CNEA/DCA/Proyectos/IV - InspeccioÌn Visual/IV/output/logs/fit/20250526_184302-model_resnet_152-pores-m250520\""
      ],
      "metadata": {
        "id": "fhtoETx8ll_o"
      },
      "id": "fhtoETx8ll_o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_type == \"resnet152\":\n",
        "  #in \"real life\" it should not be used the test set for the model selection.\n",
        "  #is just to compare with this toy example\n",
        "  X_test_resnet = preprocess_input_resnet152(X_test)\n",
        "\n",
        "  print(\"Train: \", type(X_train_resnet))\n",
        "  print(\"Val: \", type(X_val_resnet))\n",
        "  print(\"Test: \", type(X_test_resnet))\n",
        "\n",
        "  ev_train = model_resnet_152.evaluate(X_train_resnet, y_train)\n",
        "  ev_val = model_resnet_152.evaluate(X_val_resnet, y_val)\n",
        "  ev_test = model_resnet_152.evaluate(X_test_resnet, y_test)\n",
        "\n",
        "  print(f\"Train/Val/Test Loss, IoU, F1\")\n",
        "  print(ev_train, '\\n', ev_val, '\\n', ev_test)\n"
      ],
      "metadata": {
        "id": "jculXknbbcJL"
      },
      "id": "jculXknbbcJL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##VGG19"
      ],
      "metadata": {
        "id": "R1eTRZy2RILD"
      },
      "id": "R1eTRZy2RILD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce3612f-0487-42e4-bd4e-aba51942a9a9",
      "metadata": {
        "id": "5ce3612f-0487-42e4-bd4e-aba51942a9a9"
      },
      "outputs": [],
      "source": [
        "if model_vgg19 is not None:\n",
        "  print(\"VGG19\")\n",
        "  print(\"Training...\")\n",
        "  # Preprocess input for VGG19\n",
        "\n",
        "  X_train_vgg = preprocess_input_vgg19(X_train)\n",
        "  X_val_vgg = preprocess_input_vgg19(X_val)\n",
        "  X_test_vgg = preprocess_input_vgg19(X_test)\n",
        "\n",
        "  model_vgg19.fit(\n",
        "      x=X_train_vgg,\n",
        "      y=y_train,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=(X_val_vgg, y_val),\n",
        "      callbacks=[early_stopping_cb]\n",
        "  )\n",
        "\n",
        "  print(\"Saving Model...\")\n",
        "  model_vgg19.save('model_vgg19.keras')\n",
        "\n",
        "  X_test_vgg = preprocess_input_vgg19(X_test)\n",
        "\n",
        "  print(\"vgg 19\")\n",
        "  print(\"Validation results...\")\n",
        "  model_vgg19.evaluate(X_val_vgg, y_val)\n",
        "\n",
        "  print(\"Test results...\")\n",
        "  model_vgg19.evaluate(X_test_vgg, y_test)\n",
        "\n",
        "  pred_vgg19 = model_vgg19.predict(X_test_vgg)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNvuEYZ8AWHB"
      },
      "id": "HNvuEYZ8AWHB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Efficientnetb2"
      ],
      "metadata": {
        "id": "e7wELIQoRN7C"
      },
      "id": "e7wELIQoRN7C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f0d00f-3e2e-44b8-8f05-ecf0c237d159",
      "metadata": {
        "id": "c3f0d00f-3e2e-44b8-8f05-ecf0c237d159"
      },
      "outputs": [],
      "source": [
        "if model_efficientnetb2 is not None:\n",
        "  print(\"Efficientnetb2\")\n",
        "  print(\"Training...\")\n",
        "\n",
        "  X_train_eficient = preprocess_input_efficientnetb2(X_train)\n",
        "  X_val_eficient = preprocess_input_efficientnetb2(X_val)\n",
        "\n",
        "  model_efficientnetb2.fit(\n",
        "      x=X_train_eficient,\n",
        "      y=y_train,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=(X_val_eficient, y_val),\n",
        "      callbacks=[early_stopping_cb]\n",
        "  )\n",
        "\n",
        "  print(\"Saving Model...\")\n",
        "  model_efficientnetb2.save('model_efficientnetb2.keras')\n",
        "\n",
        "  X_test_eficient = preprocess_input_efficientnetb2(X_test)\n",
        "\n",
        "  print(\"Efficientnetb2\")\n",
        "  print(\"Validation results...\")\n",
        "  model_efficientnetb2.evaluate(X_val_eficient, y_val)\n",
        "\n",
        "  print(\"Test results...\")\n",
        "  model_efficientnetb2.evaluate(X_test_eficient, y_test)\n",
        "\n",
        "  pred_efficientnetb2 = model_efficientnetb2.predict(X_test_eficient)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test"
      ],
      "metadata": {
        "id": "Vp8blfRaI6Nh"
      },
      "id": "Vp8blfRaI6Nh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Librerias"
      ],
      "metadata": {
        "id": "qdcdb0j3xmUI"
      },
      "id": "qdcdb0j3xmUI"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# def create_mask(pred_mask):\n",
        "#     thresholded_arr = np.where(pred_mask > 0.5, 1, 0)\n",
        "#     return thresholded_arr\n",
        "\n",
        "def aplicar_mascara(imagen, mascara, color = [0, 255, 0]):\n",
        "    # Convertir la mÃ¡scara a un arreglo booleano\n",
        "    mascara = mascara.astype(bool)\n",
        "    mascara_exp = np.squeeze(mascara)\n",
        "    # Crear una copia de la imagen original\n",
        "    imagen_con_mascara = np.copy(imagen)\n",
        "\n",
        "    # Asignar el valor (0, 255, 0) a los pÃ­xeles donde la mÃ¡scara es verdadera\n",
        "    imagen_con_mascara[mascara_exp] = color\n",
        "\n",
        "    return imagen_con_mascara\n",
        "\n",
        "def save_image(image_array, mask, fname):\n",
        "    # print(f\"save: {fname}\")\n",
        "    # image_array_scaled = (image_array * 255).astype(np.uint8)\n",
        "    image_array_scaled = (image_array).astype(np.uint8)\n",
        "    image_mask = aplicar_mascara(image_array_scaled, mask)\n",
        "    image_out = np.concatenate((image_array_scaled, image_mask), axis=1)\n",
        "    cv2.imwrite(fname, image_out)\n",
        "\n",
        "def save_eval(images, predictions, masks, dst_fldr):\n",
        "    os.makedirs(dst_fldr, exist_ok=True)\n",
        "    if not len(images) == len(predictions):\n",
        "        raise(f\"El conjunto de imÃ¡genes y de predicciones debe tener el mismo tamaÃ±o {len(images)} != {len(predictions)}\")\n",
        "\n",
        "    os.makedirs(dst_fldr, exist_ok=True)\n",
        "    for pos in range(len(predictions)):\n",
        "        pred = np.where(predictions[pos] <= 0.5, 0, 1)\n",
        "        save_image(images[pos], pred, os.path.join(dst_fldr,f\"{pos:04}.jpg\"))\n",
        "        if masks is not None:\n",
        "            save_image(images[pos], masks[pos], os.path.join(dst_fldr,f\"{pos:04}_mask.jpg\"))\n",
        "\n",
        "def plot_all(images, masks, predictions):\n",
        "  for i in range(len(predictions)):\n",
        "    plot_img_mask(np.int64(images[i]), masks[i], predictions[i])"
      ],
      "metadata": {
        "id": "ldrlcC_MJEWh"
      },
      "id": "ldrlcC_MJEWh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entorno"
      ],
      "metadata": {
        "id": "8Q9ebiprOtKL"
      },
      "id": "8Q9ebiprOtKL"
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id = \"20250416_165203-model_resnet_152\"\n",
        "# model_id = \"20250522_173338-model_resnet_152-pores-m250520\"\n",
        "\n",
        "model_id = \"20250421_204907-VGG19-pores\"\n",
        "model_fn = f'{base_path}/output/models/{model_id}.keras'\n",
        "# 20250421_213428-model_resnet_152-cachaduras'\n",
        "\n",
        "ds_base_path = f'{base_path}/Images'\n",
        "# ds_base_path = f'E:/Data/IV/exp20250127'\n",
        "\n",
        "out_folder = f\"{base_path}/output/test/{model_id}\"\n",
        "\n",
        "th = 0.5"
      ],
      "metadata": {
        "id": "6jIXnSxmOrPz"
      },
      "id": "6jIXnSxmOrPz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carga Modelo"
      ],
      "metadata": {
        "id": "mpY1h1OkqUNS"
      },
      "id": "mpY1h1OkqUNS"
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(model_fn):\n",
        "  print(f'Weights file inexistente \"{model_fn}\"')\n",
        "else:\n",
        "  print(f'Cargando modelo \"{model_fn}\"')\n",
        "  # model_resnet_152.load_weights(model_fn)\n",
        "  model_vgg19.load_weights(model_fn)"
      ],
      "metadata": {
        "id": "jczm8hUtqTJ5"
      },
      "id": "jczm8hUtqTJ5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Test"
      ],
      "metadata": {
        "id": "xSlydADTXxRH"
      },
      "id": "xSlydADTXxRH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prueba imagenes archivos\n",
        "Imagenes no necesariamente del dataset de entrenamiento"
      ],
      "metadata": {
        "id": "KkIruI_Qspbp"
      },
      "id": "KkIruI_Qspbp"
    },
    {
      "cell_type": "code",
      "source": [
        "from fnmatch import fnmatch\n",
        "\n",
        "image_directory = f'{ds_base_path}/Output_imÃ¡genes y mÃ¡scaras 20250318/pellets'\n",
        "# image_directory = f'{ds_base_path}/250127_p_2'\n",
        "# image_directory = f'{ds_base_path}/Output Img y Mask 20250318/pellets'\n",
        "# pattern = \"250127-r1-i0-*_B4.png\"\n",
        "\n",
        "# image_filenames = [os.path.basename(image_path) for image_path in os.listdir(image_directory) if fnmatch(image_path, pattern)]\n",
        "\n",
        "# Leer lista desde archivo\n",
        "with open(f'{base_path}/output/filenames_test.txt', 'r', encoding='utf-8') as f:\n",
        "    image_filenames = [linea.strip() for linea in f]\n",
        "\n",
        "images = load_images(image_directory, image_filenames, norm=False)\n",
        "\n",
        "print(len(images))"
      ],
      "metadata": {
        "id": "ELBPAtaisHYJ"
      },
      "id": "ELBPAtaisHYJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QC4bF6PJVokR"
      },
      "id": "QC4bF6PJVokR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_resnet = preprocess_input_resnet152(np.array(images))\n",
        "pred_resnet_152 = model_resnet_152.predict(images_resnet)"
      ],
      "metadata": {
        "id": "W7sa-LHisa2h"
      },
      "id": "W7sa-LHisa2h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_vgg19 = preprocess_input_vgg19(np.array(images))\n",
        "pred_vgg19 = model_vgg19.predict(images_vgg19)"
      ],
      "metadata": {
        "id": "KD-znVH2U6jo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "KD-znVH2U6jo"
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions = pred_resnet_152\n",
        "predictions = pred_vgg19\n",
        "fnames = image_filenames\n",
        "os.makedirs(out_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not len(images) == len(predictions):\n",
        "    raise(f\"El conjunto de imÃ¡genes y de predicciones debe tener el mismo tamaÃ±o {len(images)} != {len(predictions)}\")\n",
        "\n",
        "pred_bin = [np.where(p <= th, 0, 1).astype(np.uint8) for p in predictions]\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    image = images[i].astype(np.uint8)\n",
        "    image_mask = aplicar_mascara(image, pred_bin[i])\n",
        "    image_out = np.concatenate((image, image_mask), axis=1)\n",
        "\n",
        "    fname = os.path.join(out_folder, f\"{os.path.splitext(fnames[i])[0]}_comp{os.path.splitext(fnames[i])[1]}\")\n",
        "    cv2.imwrite(fname, image_out)\n",
        "\n",
        "    fname = os.path.join(out_folder, f\"{os.path.splitext(fnames[i])[0]}_pred{os.path.splitext(fnames[i])[1]}\")\n",
        "    cv2.imwrite(fname, pred_bin[i] * 255)"
      ],
      "metadata": {
        "id": "WKiuD9uGtu-p"
      },
      "id": "WKiuD9uGtu-p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prueba Test dataset\n",
        "Conjunto Test del entrenamiento"
      ],
      "metadata": {
        "id": "qx9zQPe9wORJ"
      },
      "id": "qx9zQPe9wORJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar primero la celda de carga de conjunto de entrenamiento\n",
        "X_test, y_test, filenames_test,  = test_dataset(image_directory, masks_directory, seed=42, norm=False) # Tienen que usar los mismos parÃ¡metros que augmented_dataset en el entrenamiento\n",
        "\n",
        "X_test_resnet = preprocess_input_resnet152(X_test)\n"
      ],
      "metadata": {
        "id": "8NDVlFWKbTs6"
      },
      "id": "8NDVlFWKbTs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(image_directory), type(masks_directory))"
      ],
      "metadata": {
        "id": "8iU2uQ8fwGOG"
      },
      "id": "8iU2uQ8fwGOG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(pred_resnet_152)):\n",
        "  plot_img_mask(X_test, y_test, pred_resnet_152)"
      ],
      "metadata": {
        "id": "_Y7Yn1zXaj3T"
      },
      "id": "_Y7Yn1zXaj3T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test"
      ],
      "metadata": {
        "id": "atSR_wZ4I-Kh"
      },
      "id": "atSR_wZ4I-Kh"
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_test_resnet), type(y_test))\n",
        "print(len(X_test_resnet), y_test.shape)"
      ],
      "metadata": {
        "id": "jKitnTNxcRjX"
      },
      "id": "jKitnTNxcRjX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_folder = f\"{base_path}/output/test/20250416_165203-model_resnet_152\"\n",
        "\n",
        "# os.makedirs(out_folder, exist_ok=True)\n",
        "\n",
        "X_test_resnet = preprocess_input_resnet152(np.array(X_test))\n",
        "pred_resnet = model_resnet_152.predict(X_test_resnet)\n",
        "\n",
        "# loss, iou, f1 = model_resnet_152.evaluate(X_test_resnet, y_test)\n",
        "# print(f\"Test Loss: {loss}, IoU: {iou}, F1: {f1}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9AMpbP38FMFb"
      },
      "id": "9AMpbP38FMFb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_eval(X_test,pred_resnet,y_test,out_folder)"
      ],
      "metadata": {
        "id": "YV5tLw5e4AjS"
      },
      "id": "YV5tLw5e4AjS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_train)):\n",
        "  if np.max(y_train[i]) > 0.0 and np.max(y_train[i]) < 255:\n",
        "    print(i, np.max(y_train[i]), filenames_train[i])\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  if np.max(y_test[i]) > 0.0 and np.max(y_test[i]) < 255:\n",
        "    print(i, np.max(y_test[i]), filenames_test[i])\n",
        "\n",
        "for i in range(len(y_val)):\n",
        "  if np.max(y_val[i]) > 0.0 and np.max(y_val[i]) < 255:\n",
        "    print(i, np.max(y_val[i]), filenames_val[i])\n",
        "\n",
        "# np.max(y_train[617])"
      ],
      "metadata": {
        "id": "VjZgz75s3EVT"
      },
      "id": "VjZgz75s3EVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filenames_test)"
      ],
      "metadata": {
        "id": "-eOk7i3NuMwL"
      },
      "id": "-eOk7i3NuMwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_base_path = f'{base_path}/Images'\n",
        "# ds_base_path = f'E:/Data/IV/exp20250127'\n",
        "from fnmatch import fnmatch\n",
        "\n",
        "\n",
        "image_directory = f'{ds_base_path}/Output_imÃ¡genes y mÃ¡scaras 20250318/pellets_B4'\n",
        "# masks_directory = f'{ds_base_path}/Output_imÃ¡genes y mÃ¡scaras 20250318/all_pores'\n",
        "\n",
        "# image_directory = f'{ds_base_path}/250127_p_2'\n",
        "# image_directory = f'{ds_base_path}/Output Img y Mask 20250318/pellets'\n",
        "# masks_directory = f'{ds_base_path}/Output Img y Mask 20250318/mask_pores'\n",
        "# print(os.listdir(masks_directory))\n",
        "pattern = \"250127-r1-*_B4.png\"\n",
        "# pattern = \"250127-r1-BA-avg_A4.png\"\n",
        "\n",
        "image_filenames = [os.path.basename(image_path) for image_path in os.listdir(image_directory) if fnmatch(image_path, pattern)]\n",
        "# masks = load_masks(masks_directory, image_filenames)\n",
        "masks = None\n",
        "images = load_images(image_directory, image_filenames, norm=False)\n",
        "\n",
        "print(len(images))\n",
        "if not masks is None:\n",
        "    print(len(masks))"
      ],
      "metadata": {
        "id": "Zn3XGHlTwG26"
      },
      "id": "Zn3XGHlTwG26",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_resnet_short = preprocess_input_resnet152(np.array(images))\n",
        "pred_resnet_152 = model_resnet_152.predict(X_test_resnet_short)"
      ],
      "metadata": {
        "id": "Vwi14nRnwRHS"
      },
      "id": "Vwi14nRnwRHS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_folder = f\"{base_path}/output/test/20250416_165203-model_resnet_152\"\n",
        "os.makedirs(out_folder, exist_ok=True)\n",
        "print(out_folder)"
      ],
      "metadata": {
        "id": "ipA61i9swU_G"
      },
      "id": "ipA61i9swU_G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pred_resnet_152\n",
        "dst_fldr = out_folder\n",
        "fnames = image_filenames\n",
        "\n",
        "if not len(images) == len(predictions):\n",
        "    raise(f\"El conjunto de imÃ¡genes y de predicciones debe tener el mismo tamaÃ±o {len(images)} != {len(predictions)}\")\n",
        "\n",
        "for i in range(len(predictions)):\n",
        "    pred = np.where(predictions[i] <= 0.5, 0, 1)\n",
        "    image = images[i].astype(np.uint8)\n",
        "    image_mask = aplicar_mascara(image, pred.astype(np.uint8))\n",
        "    image_out = np.concatenate((image, image_mask), axis=1)\n",
        "    fname = os.path.join(dst_fldr,\n",
        "                        f\"{os.path.splitext(fnames[i])[0]}_pred{os.path.splitext(fnames[i])[1]}\"\n",
        "                         )\n",
        "    cv2.imwrite(fname, image_out)"
      ],
      "metadata": {
        "id": "t_LQo2OuwawG"
      },
      "id": "t_LQo2OuwawG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ryDySnX4psf8",
        "Y6FbynbEtxDc",
        "nCOSxDTSQvyK",
        "R1eTRZy2RILD",
        "e7wELIQoRN7C",
        "qdcdb0j3xmUI"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}